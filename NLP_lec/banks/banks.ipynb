{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install -Uq tensorflow\n",
    "%pip install -Uq nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('banks.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NLTKTokenizer:\n",
    "    def tokenize_text(self, text):\n",
    "        return word_tokenize(text)\n",
    "    \n",
    "tokenizer_nltk = NLTKTokenizer()\n",
    "data['text_nltk'] = data['Text'].apply(tokenizer_nltk.tokenize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "vectorizer_nltk = CountVectorizer(tokenizer=tokenizer_nltk.tokenize_text)\n",
    "X_vectorized_nltk = vectorizer_nltk.fit_transform(data['Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_nltk, X_test_nltk, y_train_nltk, y_test_nltk = train_test_split(X_vectorized_nltk, data['Score'], test_size=0.5, random_state=35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (Logistic Regression - NLTK): 0.9422857142857143\n",
      "\n",
      "Classification Report (Logistic Regression - NLTK):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.93      0.95      0.94      3477\n",
      "    Positive       0.95      0.93      0.94      3523\n",
      "\n",
      "    accuracy                           0.94      7000\n",
      "   macro avg       0.94      0.94      0.94      7000\n",
      "weighted avg       0.94      0.94      0.94      7000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logistic_model_nltk = LogisticRegression()\n",
    "logistic_model_nltk.fit(X_train_nltk, y_train_nltk)\n",
    "y_pred_logistic_nltk = logistic_model_nltk.predict(X_test_nltk)\n",
    "accuracy_logistic_nltk = accuracy_score(y_test_nltk, y_pred_logistic_nltk)\n",
    "print('Accuracy (Logistic Regression - NLTK):', accuracy_logistic_nltk)\n",
    "print('\\nClassification Report (Logistic Regression - NLTK):\\n', classification_report(y_test_nltk, y_pred_logistic_nltk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_keras = Tokenizer()\n",
    "tokenizer_keras.fit_on_texts(data['Text'])\n",
    "X_tokenized_keras = tokenizer_keras.texts_to_sequences(data['Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_padded_keras = pad_sequences(X_tokenized_keras)\n",
    "y_encoded_keras = data['Score'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_keras, X_test_keras, y_train_keras, y_test_keras = train_test_split(X_padded_keras, y_encoded_keras, test_size=0.5, random_state=35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_keras = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(len(tokenizer_keras.word_index) + 1, 100, input_length=X_padded_keras.shape[1]),\n",
    "    tf.keras.layers.Conv1D(128, 5, activation='relu'),\n",
    "    tf.keras.layers.GlobalMaxPooling1D(),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model_keras.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_keras = LabelEncoder()\n",
    "y_train_keras_encoded = encoder_keras.fit_transform(y_train_keras)\n",
    "y_test_keras_encoded = encoder_keras.transform(y_test_keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "197/197 - 195s - loss: 0.4510 - accuracy: 0.8068 - val_loss: 0.2358 - val_accuracy: 0.9229 - 195s/epoch - 989ms/step\n",
      "Epoch 2/5\n",
      "197/197 - 155s - loss: 0.1442 - accuracy: 0.9489 - val_loss: 0.2142 - val_accuracy: 0.9214 - 155s/epoch - 784ms/step\n",
      "Epoch 3/5\n",
      "197/197 - 153s - loss: 0.0401 - accuracy: 0.9906 - val_loss: 0.2355 - val_accuracy: 0.9214 - 153s/epoch - 775ms/step\n",
      "Epoch 4/5\n",
      "197/197 - 153s - loss: 0.0082 - accuracy: 0.9992 - val_loss: 0.2610 - val_accuracy: 0.9214 - 153s/epoch - 776ms/step\n",
      "Epoch 5/5\n",
      "197/197 - 152s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.2764 - val_accuracy: 0.9171 - 152s/epoch - 772ms/step\n",
      "219/219 [==============================] - 46s 212ms/step - loss: 0.2039 - accuracy: 0.9346\n",
      "Accuracy (Neural Network - Keras): 0.9345714449882507\n"
     ]
    }
   ],
   "source": [
    "model_keras.fit(X_train_keras, y_train_keras_encoded, epochs=5, batch_size=32, validation_split=0.1, verbose=2)\n",
    "_, accuracy_keras = model_keras.evaluate(X_test_keras, y_test_keras_encoded)\n",
    "print('Accuracy (Neural Network - Keras):', accuracy_keras)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "219/219 [==============================] - 46s 210ms/step - loss: 0.0290 - accuracy: 0.9917\n",
      "Accuracy: 99.2\n"
     ]
    }
   ],
   "source": [
    "_, accuracy = model_keras.evaluate(X_train_keras, y_train_keras_encoded)\n",
    "print('Accuracy: %.1f' % (accuracy * 100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
